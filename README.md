# ArXiv Scraper - Computation and Language (cs.CL)

Nome: Rudi C√©sar Comiotto Modena.

Trabalho realizado em conjunto com:
- M√°rcio Leandro
- M√¥nica Mendes

Este projeto consiste em um mecanismo de extra√ß√£o de dados (**Web Scraper**) desenvolvido para coletar informa√ß√µes sobre artigos cient√≠ficos recentes da se√ß√£o _Computation and Language_ do portal **ArXiv**. O sistema extrai metadados, garante a persist√™ncia em um banco de dados anal√≠tico, arquivo CSV e utiliza esteiras de **CI/CD** para automa√ß√£o.

---

## üöÄ Funcionalidades

- **Extra√ß√£o Automatizada:** Coleta de t√≠tulos, autores, datas de submiss√£o e links diretamente da URL: `https://arxiv.org/list/cs.CL/recent`.
- **Persist√™ncia em DuckDB:** Armazenamento dos dados em um banco de dados colunar de alta performance, ideal para an√°lise de dados.
- **Persist√™ncia em CSV:** Armazenamento dos dados em um arquivo CSV, formato muito utilizado em an√°lise de dados.
- **Containeriza√ß√£o:** Aplica√ß√£o totalmente empacotada em Docker para garantir a reprodutibilidade.
- **Automa√ß√£o CI/CD:** Pipeline configurado no GitHub Actions para build e push autom√°tico da imagem para o Docker Hub.

---

## üõ†Ô∏è Stack Tecnol√≥gica

| Camada             | Tecnologia                | Finalidade                                       |
| :----------------- | :------------------------ | :----------------------------------------------- |
| **Linguagem**      | Python 3.11               | L√≥gica de scraping e processamento               |
| **Ambiente**       | Poetry                    | Gerenciamento de depend√™ncias e ambiente virtual |
| **Web Scraping**   | BeautifulSoup4 / Requests | Parsing de HTML e requisi√ß√µes HTTP               |
| **Banco de Dados** | DuckDB                    | Persist√™ncia de dados local em formato OLAP      |
| **Exportar Dados** | CSV                       | Persist√™ncia de dados local em formato texto     |
| **Container**      | Docker                    | Portabilidade e isolamento                       |
| **CI/CD**          | GitHub Actions            | Esteira automatizada de build e deploy           |

---

## üìÇ Estrutura de Dados (DuckDB e CSV)

Os dados s√£o armazenados na tabela `arxiv_articles` dentro do banco `data/arxiv_data.duckdb`, e tamb√©m no arquivo `data/arxiv_data.csv`.

- `arxiv_id`: ID do artigo.
- `title`: T√≠tulo completo do artigo.
- `authors`: Texto com os nomes dos autores separados por v√≠rgula.
- `subjects`: Texto com os assuntos do artigo separados por v√≠rgula..
- `abstract`: Resumo do Artigo.
- `link`: URL de acesso ao resumo/PDF.
- `submission_date`: Data de submiss√£o no ArXiv.

---

## ‚öôÔ∏è Como Executar

### 1. Execu√ß√£o Local (via Poetry)

Certifique-se de ter o Python 3.11 e o Poetry instalados.

```bash
# Instalar as depend√™ncias do projeto
poetry install

# Executar o scraper
poetry run python -m arxiv_scraper.scraper
```
