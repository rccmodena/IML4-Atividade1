# ArXiv Scraper - Computation and Language (cs.CL)

Este projeto consiste em um mecanismo de extraÃ§Ã£o de dados (**Web Scraper**) desenvolvido para coletar informaÃ§Ãµes sobre artigos cientÃ­ficos recentes da seÃ§Ã£o *Computation and Language* do portal **ArXiv**. O sistema extrai metadados, garante a persistÃªncia em um banco de dados analÃ­tico e utiliza esteiras de **CI/CD** para automaÃ§Ã£o.



---

## ğŸš€ Funcionalidades

* **ExtraÃ§Ã£o Automatizada:** Coleta de tÃ­tulos, autores, datas de submissÃ£o e links diretamente da URL: `https://arxiv.org/list/cs.CL/recent`.
* **PersistÃªncia em DuckDB:** Armazenamento dos dados em um banco de dados colunar de alta performance, ideal para anÃ¡lise de dados.
* **ContainerizaÃ§Ã£o:** AplicaÃ§Ã£o totalmente empacotada em Docker para garantir a reprodutibilidade.
* **AutomaÃ§Ã£o CI/CD:** Pipeline configurado no GitHub Actions para build e push automÃ¡tico da imagem para o Docker Hub.

---

## ğŸ› ï¸ Stack TecnolÃ³gica

| Camada | Tecnologia | Finalidade |
| :--- | :--- | :--- |
| **Linguagem** | Python 3.11 | LÃ³gica de scraping e processamento |
| **Ambiente** | Poetry | Gerenciamento de dependÃªncias e ambiente virtual |
| **Web Scraping** | BeautifulSoup4 / Requests | Parsing de HTML e requisiÃ§Ãµes HTTP |
| **Banco de Dados** | DuckDB | PersistÃªncia de dados local em formato OLAP |
| **Container** | Docker | Portabilidade e isolamento |
| **CI/CD** | GitHub Actions | Esteira automatizada de build e deploy |

---

## ğŸ“‚ Estrutura de Dados (DuckDB)

Os dados sÃ£o armazenados na tabela `arxiv_articles` dentro do banco `data/arxiv_data.duckdb`.

* `title`: TÃ­tulo completo do artigo.
* `authors`: Nomes dos autores.
* `submission_date`: Data de submissÃ£o no ArXiv.
* `link`: URL de acesso ao resumo/PDF.

---

## âš™ï¸ Como Executar

### 1. ExecuÃ§Ã£o Local (via Poetry)
Certifique-se de ter o Python 3.11 e o Poetry instalados.

```bash
# Instalar as dependÃªncias do projeto
poetry install

# Executar o scraper
poetry run python -m arxiv_scraper.scraper